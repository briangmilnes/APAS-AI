 Which modules should we implement for Chap28.
 Which lower number modules can you use?
 How many modules are going to have parallelism and in which functions/methods?
 Which algorithms, problems and exercises?
 Discuss with the user.

 Build a plan for fixing this, including test and benchmark
 using PrePlanChecklist.md. 

 Show it to me and estimate time.

 This goes in Chap28.
 
Chapter 28
Maximum Contiguous
Subsequence Sum
This chapter reviews the classic problem of finding the contiguous subsequence of a se-
quence with the maximal value, and provides several algorithms for the problem by apply-
ing several design techniques including brute force , reduction , and divide and conquer
.
1 The Problem
Definition 28.1 (Subsequence). A subsequence b of a sequence a is a sequence that can
be derived from a by deleting zero or more elements of a without changing the order of
remaining elements.
Example 28.1. Several examples follow.
• The sequence 〈 0, 2, 4 〉 is a subsequence of 〈 0, 1, 2, 2, 3, 4, 5 〉.
• The sequence 〈 2, 4, 3 〉 is a not subsequence of 〈 0, 1, 2, 2, 3, 4, 5 〉 but 〈 2, 3, 4 〉 is.
Definition 28.2 (Contiguous Subsequence). A contiguous subsequence is a subsequence
that appears contiguously in the original sequence. For any sequence a of n elements, the
subsequence
b = a[i · · · j], 0 ≤ i ≤ j < n,
consisting of the elements of a at positions i, i + 1, . . . , j is a contiguous subsequence of b.

Example 28.2. For a = 〈1, −2, 0, 3, −1, 0, 2, −3 〉, here are some contiguous subsequences:
• 〈 1 〉,
• 〈 − 2, 0, 3 〉, and
• 〈 3, −1, 0, 2, −3 〉.
The sequence 〈 − 1, 2, −3 〉 is not a contiguous subsequence, even though it is a subse-
quence.
Definition 28.3 (The Maximum Contiguous Subsequence (MCS) Problem). Given a se-
quence of integers, the Maximum Contiguous Subsequence Problem (MCS) requires find-
ing the contiguous subsequence of the sequence with maximum total sum, i.e.,
MCS (a) = arg max 0 ≤ i, j < |a|
( j∑
k=i
a[k]
)
.
We define the sum of an empty sequence to be −∞.
Example 28.3. For a = 〈 1, −2, 0, 3, −1, 0, 2, −3 〉 , a maximum contiguous subsequence is,
〈 3, −1, 0, 2 〉; another is 〈 0, 3, −1, 0, 2 〉 .
Definition 28.4 (The Maximum Contiguous Subsequence Sum (MCSS) Problem). Given a
sequence of integers, the Maximum Contiguous Subsequence Sum Problem (MCSS)
requires finding the total sum of the elements in the contiguous subsequence of the se-
quence with maximum total sum, i.e.,
MCSS (a) = max
{ j∑
k=i
a[k] : 0 ≤ i, j < |a|
}
.
Example 28.4. For a = 〈 1, −2, 0, 3, −1, 0, 2, −3 〉 〉 , a maximum contiguous subsequence is,
〈 3, −1, 0, 2 〉 ; another is 〈 0, 3, −1, 0, 2 〉 . Thus MCSS (a) = 4.
For the empty sequence, MCSS = −∞ because the sum of an empty sequence is defined
as −∞.
Note. Here we only consider sequences of integers and the addition operation to compute
the sum, the techniques that we describe should apply to sequences of other types and
other associative sum operations.

Lower Bound. To solve the MCSS problem, we need to inspect, at the very least, each
and every element of the sequence. This requires linear work in the length of the sequence
and thus solve the MCSS problem requires Ω(n) work

Note (History of the Problem). The study of maximum contiguous subsequence problem
goes to 1970’s. The problem was first proposed in by Ulf Grenander, a Swedish statistician
and a professor of applied mathematics at Brown University, in 1977. The problem has
several names, such maximum subarray sum problem, or maximum segment sum prob-
lem, the former of which appears to be the name originally used by Grenander. Grenander
intended it to be a simplified model for maximum likelihood estimation of patterns in dig-
itized images, whose structure he wanted to understand.
According to Jon Bentley (Jon Bentley, Programming Pearls (1st edition), page 76.) in 1977,
Grenander described the problem to Michael Shamos of Carnegie Mellon University who
overnight designed a divide and conquer algorithm, which corresponds to our first divide-
and-conquer algorithm . When Shamos and Bentley discussed the problem and Shamos’
solution, they thought that it was probably the best possible. A few days later Shamos
described the problem and its history at a Carnegie Mellon seminar attended by statistician
Joseph (Jay) Kadane, who designed the work efficient algorithm within a minute. Kadane’s
algorithm correspond to the linear work and span algorithm described below.
Roadmap. The remaining sections apply various algorithm-design techniques to the MCS
and MCSS problems. To exercise our vocabulary for algorithm design, the content is or-
ganized to identify carefully the design techniques, sometimes at a level of precision that
may, especially in subsequent reads, feel pedantic.

2 Brute Force
This section presents a first solution to the MCSS problem by using the brute force tech-
nique .
Algorithm 28.5 (MCSS: Brutest Force). We can solve the MCSS problem by brute force.
First, we identify the set of candidate solutions as the set of all integers. Then we enu-
merate all integers and, for each one, check that there is a contiguous subsequence whose
sum is equal to that integer. We stop when we find the largest integer with a matching
subsequence.
Perhaps obviously, such an algorithm would not terminate, because we don’t know when
to stop. Notice, however, that the solution is bounded by the sum of all positive integers in
the sequence. We can thus stop the search when we reach that bound.
This algorithm terminates but has the undesirable characteristic that its bound depends on
the values of the elements in the sequence rather that its length.
Reduction to MCS. Our first algorithm is rather inefficient in the worst case, because
it tries a large number of candidate solutions. We can achieve a better bound by reduc-
ing MCSS problem to the Maximum Contiguous Subsequence (MCS) problem , which


2. BRUTE FORCE 185
requires finding the contiguous subsequence with the largest sum.
The reduction itself is straightforward: because both problems operate on the same input,
there is no need to transform the input. To compute the output, we sum the elements in the
sequence returned by the MCS problem. Using reduce, this requires O(n) work and O(lg n)
span. Thus, the work and span of the reduction is O(n) and O(lg n) respectively.
Algorithm 28.6 (MCS: Brute Force). We can solve the MCS problem by brute force: we
enumerate all candidate solutions, which consist of all the contiguous subsequences of the
sequence, and find the one with the largest sum. To generate all contiguous subsequences,
we can generate all pairs of integers (i, j), 0 ≤ i ≤ j < n, compute the sum of the subse-
quence that corresponds to the pair, and pick the one with the largest total. We write the
algorithm as follows:
MCSBF a =
let
maxSum ((i, j, s), (k, `, t)) = if s > t then (i, j, s) else (k, `, t)
b = 〈 (i, j, reduce + 0 a[i · · · j]) : 0 ≤ i ≤ j < n 〉
(i, j, s) = reduce maxSum (−1, −1, −∞) b
in
(i, j)
end
Cost of Brute Force MCS. Using array sequence costs, generating the n2 subsequences
requires a total of O(n2) work and O(lg n) span. Reducing over each subsequence us-
ing reduce adds linear work per subsequence, bringing the total work to O(n3). The final
reduce that select the maximal subsequence require O(n2) work. The total work is thus
dominated by the computation of sums for each subsequence, and therefore is O(n3).
Because we can generate all pairs in parallel and compute their sum in parallel in Θ(lg n)
span using reduce, the algorithm requires Θ(lg n) span.
Algorithm 28.7 (MCSS: Brute Force). Our first algorithm uses brute force technique and a
reduction to the MCS problem, which we again solve by brute force using the brute-force
MCS algorithm . We can write the algorithm as follows:
MCSSBF a =
let
(i, j) = MCSBF a
sum = reduce ’ + ’ 0 a[i · · · j]
in
sum
end.
Strengthening. The brute force algorithm has some redundancy: to find the solution,
it computes the result for the MCS problem and then computes the sum of the result se-

quence, which is already computed by the MCS algorithm. We can eliminate this redun-
dancy by strengthening the MCS problem and requiring it to return the sum in addition to
the subsequence.
Exercise 28.1. Describe the changes to the algorithms Algorithm 28.6 and Algorithm 28.7 to
implement the strengthening described above. How does strengthening impact the work
and span costs?
Algorithm 28.8 (MCSS: Brute Force Strengthened). We can write the algorithm based on
strengthening directly as follows. Because the problem description requires returning only
the sum, we simplify the algorithm by not tracking the subsequences.
MCSSBF a =
let
b = 〈 reduce + 0 a[i · · · j] : 0 ≤ i ≤ j < n 〉
in
reduce max −∞ b
end
Cost Analysis. Let’s analyze the work and span of the strengthened brute-force algo-
rithm by using array sequences and by appealing to our cost bounds for reduce, subseq,
and tabulate. The cost bounds for enumerating all possible subsequences and computing
their sums is as follows.
W (n) = 1 + ∑
1≤i≤j≤n
Wreduce (j − i) ≤ 1 + n2 · Wreduce (n) = Θ(n3)
S(n) = 1 + max
1≤i≤j≤n Sreduce(j − i) ≤ 1 + Sreduce (n) = Θ(lg n)
The final step of the brute-force algorithm is to find the maximum over these Θ(n2) com-
binations. Since the reduce for this step has Θ(n2) work and Θ(lg n) span the cost of the
final step is subsumed by other costs analyzed above. Overall, we have an Θ(n3)-work
Θ(lg n)-span algorithm.
Note. Note that the span requires the maximum over (n
2
) ≤ n2 values, but since lg nk =
k lg n, this is simply Θ(lg n).
Summary. When trying to apply the brute-force technique to the MCSS problem, we
encountered a problem. We solved this problem by reducing MCSS problem to another
problem, MCS. We then realized a redundancy in the resulting algorithm and eliminated
that redundancy by strengthening MCS. This is a quite common route when designing a
good algorithm: we find ourselves refining the problem and the solution until it is (close
to) perfect.
3 Applying Reduction
In the previous section , we used the brute-force technique to develop an algorithm that has

ogarithmic span but large (cubic) work. In this section, we apply the reduction technique
to obtain a low span and work-efficient (linear work) algorithm for the MCSS problem.
3.1 Auxiliary Problems
Overlapping Subsequences and Redundancy. To understand how we might improve
the amount of work, observe that the brute-force algorithm performs a lot of repeated and
thus redundant work. To see why, consider the subsequences that start at some location.
For each position, e.g., the middle, the algorithm considers a subsequence that starts at the
position and at any other position that comes after it. Even though each subsequence dif-
fers from another by a single element (in the ending positions), the algorithm computes
the total sum for each of these subsequences independently, requiring linear work per
subsequence. The algorithm does not take advantage of the overlap between the many
subsequences it considers.
Reducing Redundancy. We can reduce redundancy by taking advantage of the overlaps
and computing all subsequences that start or end at a given position together. Our basic
strategy in applying the reduction technique is to use this observation. To this end, we
define two problems that are closely related to the MCSS problem, present efficient and
parallel algorithm for these problems, and then reduce the MCSS to them.
Definition 28.9 (MCSSS). The Maximum Contiguous Subsequence Sum with Start, ab-
breviated MCSSS, problem requires finding the maximum contiguous subsequence of a
sequence that starts at a given position.

Definition 28.10 (MCSSE Problem). The Maximum Contiguous Subsequence with Ending,
i.e., the MCSSE problem requires finding the maximum contiguous subsequence ending
at a specified end position.
Reducing MCSS to MCSSS and MCSSE. Observe that we can reduce the MCSS prob-
lem to MCSSS problem by enumerating over all starting positions, solving MCSSS for
each position, and taking the maximum over the results. A similar reduction works for the
MCSSE problem.
Because the inputs to all these problems are essentially the same, we don’t need to trans-
form the input. To compute the output for MCSS, we need to perform a reduce. The
reduction itself is thus efficient.
Algorithm 28.11 (An Optimal Alggorithm for MCSSS). We can solve the MCSSS problem
by first computing the sum for all subsequences that start at the given position using scan

